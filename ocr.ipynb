{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa20132d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2509622762.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install \"numpy<2\" \"rembg[cpu]\" easyocr pytesseract\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (pin NumPy < 2 to avoid binary-compat errors)\n",
    "pip install \"numpy<2\" \"rembg[cpu]\" easyocr pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6488a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file picker...\n",
      "Selected: C:/Users/Omar/Downloads/WhatsApp Image 2026-01-27 at 1.48.35 PM.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "first name عمر\n",
      "seconed name احمد حافظ عبدالحليم حافظ\n",
      "address ٠٧ زهراء نصر مدينة نصراول - القاهره\n",
      "id 29305130103094\n",
      "birthdate 1993-05-13\n",
      "error 0\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "from tkinter import filedialog\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "from easyocr import easyocr\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import string\n",
    "from datetime import datetime\n",
    "# from OCR_Endpoint import settings\n",
    "\n",
    "# Set Tesseract path and tessdata directory\n",
    "pytesseract.pytesseract.tesseract_cmd = r'D:\\ocr\\tesseract\\tesseract.exe'\n",
    "os.environ['TESSDATA_PREFIX'] = r'D:\\ocr\\tessdata'\n",
    "\n",
    "data = {\"first name\": \"0\",\n",
    "        \"seconed name\": \"0\",\n",
    "        \"address\": \"0\",\n",
    "        \"id\": \"0\",\n",
    "        \"birthdate\": \"0\",\n",
    "        \"error\": 0}\n",
    "\n",
    "# OCR configuration\n",
    "TESS_LANG_TEXT = \"ara\"\n",
    "TESS_LANG_ID = \"ara\"\n",
    "TESS_CONFIG_TEXT = \"--psm 11 --oem 3\"\n",
    "TESS_CONFIG_ID = \"--psm 7 --oem 3\"\n",
    "\n",
    "ARABIC_DIGITS = [\"٠\", \"١\", \"٢\", \"٣\", \"٤\", \"٥\", \"٦\", \"٧\", \"٨\", \"٩\"]\n",
    "PUN = set(string.punctuation)\n",
    "_ARABIC_TO_WESTERN = str.maketrans('٠١٢٣٤٥٦٧٨٩', '0123456789')\n",
    "_WESTERN_TO_ARABIC = str.maketrans('0123456789', '٠١٢٣٤٥٦٧٨٩')\n",
    "\n",
    "def _to_western_digits(sval: str) -> str:\n",
    "    return (sval or \"\").translate(_ARABIC_TO_WESTERN)\n",
    "\n",
    "def _to_arabic_digits(sval: str) -> str:\n",
    "    return (sval or \"\").translate(_WESTERN_TO_ARABIC)\n",
    "\n",
    "def _count_arabic_letters(sval: str) -> int:\n",
    "    return len(re.findall(r'[\\u0600-\\u06FF]', sval or \"\"))\n",
    "\n",
    "def _arabic_words(sval: str) -> list[str]:\n",
    "    return re.findall(r'[\\u0600-\\u06FF]{2,}', sval or \"\")\n",
    "\n",
    "def _clean_name(sval: str) -> str:\n",
    "    sval = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', sval or \"\")\n",
    "    return ' '.join(sval.split())\n",
    "\n",
    "def _choose_names(t_lines: list[str], easy_tokens: list[str]) -> tuple[str, str, list[str]]:\n",
    "    t_first = _clean_name(t_lines[0]) if len(t_lines) > 0 else \"\"\n",
    "    t_second = _clean_name(t_lines[2]) if len(t_lines) > 2 else \"\"\n",
    "    easy_words: list[str] = []\n",
    "    for tok in easy_tokens:\n",
    "        easy_words.extend(_arabic_words(tok))\n",
    "    e_first = easy_words[0] if len(easy_words) > 0 else \"\"\n",
    "    e_second = easy_words[1] if len(easy_words) > 1 else \"\"\n",
    "    def _best(a: str, b: str) -> str:\n",
    "        if len(a) >= 2:\n",
    "            return a\n",
    "        return b\n",
    "    first = _best(t_first, e_first) or t_first or e_first\n",
    "    second = _best(t_second, e_second) or t_second or e_second\n",
    "    if len(first) < 2 and e_first:\n",
    "        first = e_first\n",
    "    if len(second) < 2 and e_second:\n",
    "        second = e_second\n",
    "    return first or \"0\", second or \"0\", easy_words\n",
    "\n",
    "def _best_text(text_a: str, text_b: str) -> str:\n",
    "    a = text_a.strip() if text_a else \"\"\n",
    "    b = text_b.strip() if text_b else \"\"\n",
    "    if not a and not b:\n",
    "        return \"\"\n",
    "    if _count_arabic_letters(a) != _count_arabic_letters(b):\n",
    "        return a if _count_arabic_letters(a) > _count_arabic_letters(b) else b\n",
    "    return a if len(a) >= len(b) else b\n",
    "\n",
    "def _best_id_list(list_a: list[str], list_b: list[str]) -> list[str]:\n",
    "    def score(lst: list[str]) -> tuple[int, int]:\n",
    "        if not lst:\n",
    "            return (0, 0)\n",
    "        best = max(lst, key=len)\n",
    "        digits = len(re.findall(r'[0-9٠-٩]', best))\n",
    "        return (digits, len(best))\n",
    "    return list_a if score(list_a) >= score(list_b) else list_b\n",
    "\n",
    "def _sanitize_addr(sval: str) -> str:\n",
    "    \"\"\"Keep Arabic letters, digits and common separators; drop OCR garbage like > ؟ etc.\"\"\"\n",
    "    sval = (sval or \"\").replace('؟', ' ').replace('?', ' ').replace('>', ' ').replace('<', ' ')\n",
    "    # Remove English letters (a-z, A-Z)\n",
    "    sval = re.sub(r'[a-zA-Z]', ' ', sval)\n",
    "    # Remove common OCR artifacts and special characters, keep only Arabic, digits, spaces, and separators\n",
    "    sval = re.sub(r'[^\\u0600-\\u06FF0-9٠-٩\\s\\-ـ]', ' ', sval)\n",
    "    # Remove excessive spaces\n",
    "    sval = ' '.join(sval.split())\n",
    "    return sval\n",
    "\n",
    "def _extract_leading_number(sval: str) -> str:\n",
    "    sval = _sanitize_addr(sval)\n",
    "    m = re.match(r'^[0-9٠-٩]{1,6}', sval)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "def _extract_locality_prefix(sval: str) -> str:\n",
    "    \"\"\"Return the part before numbers/markers (often the area name).\"\"\"\n",
    "    sval = _sanitize_addr(sval)\n",
    "    m = re.search(r'[مقكش]|[0-9٠-٩]', sval)\n",
    "    prefix = sval[:m.start()] if m else sval\n",
    "    prefix = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', prefix)\n",
    "    prefix = ' '.join(prefix.split())\n",
    "    return prefix\n",
    "\n",
    "def _extract_longest_arabic_phrase(sval: str) -> str:\n",
    "    \"\"\"Pick the longest phrase of Arabic words (ignoring markers/digits).\"\"\"\n",
    "    sval = _sanitize_addr(sval)\n",
    "    if not sval:\n",
    "        return \"\"\n",
    "    tmp = re.sub(r'[0-9٠-٩]', ' ', sval)\n",
    "    tmp = re.sub(r'\\b[مقكش]\\b', ' ', tmp)\n",
    "    tmp = re.sub(r'[\\-ـ]', ' ', tmp)\n",
    "    tmp = ' '.join(tmp.split())\n",
    "    phrases = re.findall(r'[\\u0600-\\u06FF]{2,}(?:\\s+[\\u0600-\\u06FF]{2,}){0,3}', tmp)\n",
    "    if not phrases:\n",
    "        return \"\"\n",
    "    phrases = [' '.join(p.split()) for p in phrases]\n",
    "    phrases.sort(key=lambda p: (_count_arabic_letters(p), len(p.split()), len(p)), reverse=True)\n",
    "    return phrases[0]\n",
    "\n",
    "def _extract_all_locality_parts(sval: str) -> str:\n",
    "    \"\"\"Extract all Arabic locality parts (area, district, governorate) excluding standalone markers.\"\"\"\n",
    "    sval = _sanitize_addr(sval)\n",
    "    # Remove standalone markers (م, ق, ك, ش) when they're followed by numbers\n",
    "    cleaned = re.sub(r'\\b[مقكش]\\s*[\\-ـ:]?\\s*[0-9٠-٩]+', ' ', sval)\n",
    "    # Remove all remaining standalone numbers\n",
    "    cleaned = re.sub(r'\\b[0-9٠-٩]+\\b', ' ', cleaned)\n",
    "    # Remove standalone single letter markers that remain\n",
    "    cleaned = re.sub(r'\\b[مقكش]\\b', ' ', cleaned)\n",
    "    # Clean up extra separators\n",
    "    cleaned = re.sub(r'[\\-ـ]+', ' ', cleaned)\n",
    "    # Keep only Arabic letters and spaces\n",
    "    cleaned = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', cleaned)\n",
    "    cleaned = ' '.join(cleaned.split())\n",
    "    return cleaned.strip()\n",
    "\n",
    "def _pick_locality(addr_t: str, addr_e: str) -> str:\n",
    "    cands = []\n",
    "    for s0 in [addr_t, addr_e]:\n",
    "        # Try to extract all locality parts (including governorate)\n",
    "        full_locality = _extract_all_locality_parts(s0)\n",
    "        if full_locality:\n",
    "            cands.append(full_locality)\n",
    "        # Also try traditional methods as fallback\n",
    "        cands.append(_extract_locality_prefix(s0))\n",
    "        cands.append(_extract_longest_arabic_phrase(s0))\n",
    "    cands = [c.strip() for c in cands if c and c.strip()]\n",
    "    if not cands:\n",
    "        return \"\"\n",
    "    cands = list(dict.fromkeys(cands))\n",
    "    cands.sort(key=lambda p: (_count_arabic_letters(p), len(p.split()), len(p)), reverse=True)\n",
    "    best = cands[0]\n",
    "    if _count_arabic_letters(best) < 3:\n",
    "        raw = _sanitize_addr(addr_t)\n",
    "        raw2 = _sanitize_addr(addr_e)\n",
    "        best = raw if _count_arabic_letters(raw) >= _count_arabic_letters(raw2) else raw2\n",
    "    return best.strip()\n",
    "\n",
    "def _extract_marker_number(sval: str, marker: str) -> str:\n",
    "    sval = _sanitize_addr(sval)\n",
    "    # Match marker only when it's standalone (word boundary before it)\n",
    "    # This prevents matching م in \"مركز\" or ق in \"القنطرة\"\n",
    "    m = re.search(rf'(?:^|[\\s\\-ـ]){marker}\\s*[\\-ـ:]?\\s*([0-9٠-٩]{{1,3}})', sval)\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "def _closest_number_after_marker(sval: str, marker: str) -> str:\n",
    "    \"\"\"Pick the nearest 2-3 digit group to the marker, if it exists.\"\"\"\n",
    "    sval = _sanitize_addr(sval)\n",
    "    # Find standalone marker (not part of a word)\n",
    "    marker_idx = -1\n",
    "    for match in re.finditer(rf'(?:^|[\\s\\-ـ]){marker}(?:[\\s\\-ـ]|$)', sval):\n",
    "        marker_idx = match.start() + (1 if match.group(0)[0] in ' \\-ـ' else 0)\n",
    "        break\n",
    "    \n",
    "    if marker_idx == -1:\n",
    "        return \"\"\n",
    "    best = None\n",
    "    for m in re.finditer(r'[0-9٠-٩]{2,3}', sval):\n",
    "        dist = abs(m.start() - marker_idx)\n",
    "        cand = m.group(0)\n",
    "        if best is None or dist < best[0]:\n",
    "            best = (dist, cand)\n",
    "    return best[1] if best else \"\"\n",
    "\n",
    "def _best_number(num_t: str, num_e: str, all_digits_t: list[str], all_digits_e: list[str]) -> str:\n",
    "    \"\"\"Prefer longer numbers (2-3 digits). If only 1 digit exists, try to build 2 digits from the other OCR digits.\"\"\"\n",
    "    candidates = [x for x in [num_t, num_e] if x]\n",
    "    if not candidates:\n",
    "        return \"\"\n",
    "    candidates_sorted = sorted(candidates, key=len, reverse=True)\n",
    "    best = candidates_sorted[0]\n",
    "    if len(best) >= 2:\n",
    "        return best\n",
    "    singles = [d for d in (all_digits_t + all_digits_e) if len(d) == 1 and d != best]\n",
    "    if singles:\n",
    "        return best + singles[0]\n",
    "    return best\n",
    "\n",
    "def _extract_city_district(sval: str) -> str:\n",
    "    \"\"\"Extract city/district/governorate name from address.\"\"\"\n",
    "    known_cities = [\n",
    "        'اكتوبر', '6 اكتوبر', 'القاهرة', 'الجيزة', 'الاسكندرية', 'الاسماعيلية',\n",
    "        'بورسعيد', 'السويس', 'المنصورة', 'طنطا', 'الزقازيق', 'اسيوط', 'الفيوم',\n",
    "        'بنها', 'دمياط', 'اسوان', 'الاقصر', 'قنا', 'سوهاج', 'المنيا', 'كفر الشيخ',\n",
    "        'الدقهلية', 'الشرقية', 'الغربية', 'القليوبية', 'البحيرة', 'مطروح'\n",
    "    ]\n",
    "    sval = _sanitize_addr(sval)\n",
    "    words = sval.split()\n",
    "    \n",
    "    # Look for known city names\n",
    "    for i, word in enumerate(words):\n",
    "        for city in known_cities:\n",
    "            if city in word or word in city:\n",
    "                # Return from this position to end\n",
    "                return ' '.join(words[i:])\n",
    "    \n",
    "    # If no known city found, return last 1-2 words\n",
    "    if len(words) >= 2:\n",
    "        return ' '.join(words[-2:])\n",
    "    elif len(words) == 1:\n",
    "        return words[0]\n",
    "    return \"\"\n",
    "\n",
    "def _extract_area_name(sval: str, city: str) -> str:\n",
    "    \"\"\"Extract area name (first part before city/markers).\"\"\"\n",
    "    sval = _sanitize_addr(sval)\n",
    "    # Remove city name\n",
    "    if city:\n",
    "        sval = sval.replace(city, ' ')\n",
    "    # Remove markers and numbers\n",
    "    sval = re.sub(r'\\b[مقكش]\\s*[\\-ـ:]?\\s*[0-9٠-٩]+', ' ', sval)\n",
    "    sval = re.sub(r'\\b[0-9٠-٩]+\\b', ' ', sval)\n",
    "    sval = re.sub(r'\\b[مقكش]\\b', ' ', sval)\n",
    "    sval = re.sub(r'[\\-ـ]+', ' ', sval)\n",
    "    sval = ' '.join(sval.split())\n",
    "    return sval.strip()\n",
    "\n",
    "def choose_address(addr_tesseract: str, addr_easyocr: str) -> str:\n",
    "    \"\"\"Build a clean address using BOTH OCR outputs with multiple marker types.\"\"\"\n",
    "    addr_t = _sanitize_addr(addr_tesseract)\n",
    "    addr_e = _sanitize_addr(addr_easyocr)\n",
    "    if not addr_t and not addr_e:\n",
    "        return \"0\"\n",
    "    \n",
    "    # Extract city/district from both sources\n",
    "    city_t = _extract_city_district(addr_t)\n",
    "    city_e = _extract_city_district(addr_e)\n",
    "    city = city_t if _count_arabic_letters(city_t) >= _count_arabic_letters(city_e) else city_e\n",
    "    \n",
    "    # Extract area name (without city)\n",
    "    area_t = _extract_area_name(addr_t, city)\n",
    "    area_e = _extract_area_name(addr_e, city)\n",
    "    area = area_t if _count_arabic_letters(area_t) >= _count_arabic_letters(area_e) else area_e\n",
    "    \n",
    "    # Support multiple marker types: م (meem), ق (qaf), ك (kaf), ش (sheen)\n",
    "    markers = {}\n",
    "    possible_markers = ['م', 'ق', 'ك', 'ش']\n",
    "    \n",
    "    for marker in possible_markers:\n",
    "        m_t = _extract_marker_number(addr_t, marker)\n",
    "        m_e = _extract_marker_number(addr_e, marker)\n",
    "        \n",
    "        if not m_t and not m_e:\n",
    "            continue\n",
    "            \n",
    "        m2_t = _closest_number_after_marker(addr_t, marker)\n",
    "        m2_e = _closest_number_after_marker(addr_e, marker)\n",
    "        \n",
    "        all_t = [_to_western_digits(x) for x in re.findall(r'[0-9٠-٩]+', addr_t)]\n",
    "        all_e = [_to_western_digits(x) for x in re.findall(r'[0-9٠-٩]+', addr_e)]\n",
    "        \n",
    "        best = _best_number(_to_western_digits(m2_t or m_t), _to_western_digits(m2_e or m_e), all_t, all_e)\n",
    "        \n",
    "        if len(best) == 1:\n",
    "            twos = [d for d in (all_t + all_e) if len(d) == 2]\n",
    "            if twos:\n",
    "                best = twos[-1]\n",
    "        \n",
    "        if best:\n",
    "            markers[marker] = _to_arabic_digits(best)\n",
    "    \n",
    "    result = \"\"\n",
    "    if len(markers) == 0:\n",
    "        result = f\"{area} {city}\".strip() or addr_e or addr_t\n",
    "    elif len(markers) == 1:\n",
    "        marker, number = list(markers.items())[0]\n",
    "        result = f\"{area} {marker} {number} {city}\".strip()\n",
    "    elif len(markers) == 2:\n",
    "        items = list(markers.items())\n",
    "        result = f\"{area} {items[0][0]} {items[0][1]} -{items[1][0]} {items[1][1]} {city}\".strip()\n",
    "    else:\n",
    "        marker_str = ' -'.join([f\"{k} {v}\" for k, v in markers.items()])\n",
    "        result = f\"{area} {marker_str} {city}\".strip()\n",
    "    \n",
    "    lead_t = _extract_leading_number(addr_t)\n",
    "    lead_e = _extract_leading_number(addr_e)\n",
    "    lead = lead_t if len(lead_t) >= len(lead_e) else lead_e\n",
    "    if lead:\n",
    "        lead = _to_arabic_digits(_to_western_digits(lead))\n",
    "        if not result.startswith(lead):\n",
    "            result = f\"{lead} {result}\".strip()\n",
    "    \n",
    "    # Final cleanup: remove any remaining English letters or special characters\n",
    "    result = re.sub(r'[a-zA-Z]', '', result)\n",
    "    result = re.sub(r'[^\\u0600-\\u06FF0-9٠-٩\\s\\-ـ]', ' ', result)\n",
    "    result = ' '.join(result.split())\n",
    "    return result\n",
    "\n",
    "def _remove_cross_line_duplicates(address: str) -> str:\n",
    "    \"\"\"Remove duplicate words that appear in multiple parts of the address.\n",
    "    If a word appears in multiple parts, keep it only in the last occurrence.\"\"\"\n",
    "    if not address or address == \"0\":\n",
    "        return address\n",
    "    \n",
    "    def _dedupe_line(line: str) -> str:\n",
    "        normalized = line\n",
    "        for marker in ['م', 'ق', 'ك', 'ش']:\n",
    "            normalized = normalized.replace(f'-{marker}', f'- {marker}')\n",
    "            normalized = normalized.replace(f'ـ{marker}', f'ـ {marker}')\n",
    "    \n",
    "        parts = re.split(r'\\s+', normalized)\n",
    "        if len(parts) <= 1:\n",
    "            return line\n",
    "    \n",
    "        # Track words and marker+number combinations\n",
    "        word_positions = {}\n",
    "        i = 0\n",
    "        while i < len(parts):\n",
    "            word = parts[i]\n",
    "    \n",
    "            # Check if this token contains a marker+number combo (e.g., \"م٢٦\" or \"ق٢٦\")\n",
    "            marker_num_match = re.match(r'^([مقكش])([0-9٠-٩]+)$', word)\n",
    "            if marker_num_match:\n",
    "                marker = marker_num_match.group(1)\n",
    "                number = marker_num_match.group(2)\n",
    "                combo = f\"{marker} {number}\"\n",
    "                if combo not in word_positions:\n",
    "                    word_positions[combo] = []\n",
    "                word_positions[combo].append(i)\n",
    "                i += 1\n",
    "                continue\n",
    "    \n",
    "            # Check if this is a marker followed by a number in the next token\n",
    "            if word in ['م', 'ق', 'ك', 'ش'] and i + 1 < len(parts) and re.match(r'^[0-9٠-٩]+$', parts[i + 1]):\n",
    "                combo = f\"{word} {parts[i + 1]}\"\n",
    "                if combo not in word_positions:\n",
    "                    word_positions[combo] = []\n",
    "                word_positions[combo].append((i, i + 1))\n",
    "                i += 2\n",
    "                continue\n",
    "    \n",
    "            # Skip standalone markers, numbers, and separators\n",
    "            if word in ['م', 'ق', 'ك', 'ش', '-', 'ـ'] or re.match(r'^[0-9٠-٩]+$', word):\n",
    "                i += 1\n",
    "                continue\n",
    "    \n",
    "            # Regular word\n",
    "            if word not in word_positions:\n",
    "                word_positions[word] = []\n",
    "            word_positions[word].append(i)\n",
    "            i += 1\n",
    "    \n",
    "        # Mark positions to remove (keep only the last occurrence of duplicates)\n",
    "        positions_to_remove = set()\n",
    "        for item, positions in word_positions.items():\n",
    "            if len(positions) > 1:\n",
    "                for pos in positions[:-1]:\n",
    "                    if isinstance(pos, tuple):\n",
    "                        positions_to_remove.add(pos[0])\n",
    "                        positions_to_remove.add(pos[1])\n",
    "                    else:\n",
    "                        positions_to_remove.add(pos)\n",
    "    \n",
    "        # Rebuild address without removed positions\n",
    "        cleaned_parts = [parts[i] for i in range(len(parts)) if i not in positions_to_remove]\n",
    "        return ' '.join(cleaned_parts)\n",
    "    \n",
    "    lines = address.splitlines()\n",
    "    cleaned_lines = [_dedupe_line(line) for line in lines]\n",
    "    if len(cleaned_lines) == 1:\n",
    "        return cleaned_lines[0]\n",
    "    return '\\n'.join([line for line in cleaned_lines if line.strip()])\n",
    "\n",
    "def _pick_file() -> str:\n",
    "    try:\n",
    "        wi = Tk()\n",
    "        wi.withdraw()\n",
    "        wi.attributes('-topmost', True)\n",
    "        wi.update()\n",
    "        print(\"Opening file picker...\")\n",
    "        file_path = filedialog.askopenfilename(parent=wi, title=\"choose image\")\n",
    "        wi.destroy()\n",
    "        return file_path\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def _preprocess_for_ocr_light(img: np.ndarray) -> np.ndarray:\n",
    "    if img is None:\n",
    "        return img\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th\n",
    "\n",
    "def _extract_birthdate_from_id(id_value: str) -> str:\n",
    "    digits = re.sub(r'\\D', '', _to_western_digits(str(id_value)))\n",
    "    if len(digits) < 7:\n",
    "        return \"0\"\n",
    "    # Egyptian-style 14-digit ID: CYYMMDD... where C=2 (1900s) or 3 (2000s)\n",
    "    if len(digits) >= 7 and digits[0] in ('2', '3') and len(digits) >= 7:\n",
    "        century = 1900 if digits[0] == '2' else 2000\n",
    "        yy = int(digits[1:3])\n",
    "        mm = int(digits[3:5])\n",
    "        dd = int(digits[5:7])\n",
    "        try:\n",
    "            dt = datetime(century + yy, mm, dd)\n",
    "            return dt.strftime('%Y-%m-%d')\n",
    "        except Exception:\n",
    "            return \"0\"\n",
    "    # Fallback: if 6 digits found (YYMMDD) at start, assume 19xx/20xx based on year\n",
    "    if len(digits) >= 6:\n",
    "        yy = int(digits[0:2])\n",
    "        mm = int(digits[2:4])\n",
    "        dd = int(digits[4:6])\n",
    "        century = 2000 if yy <= (datetime.now().year % 100) else 1900\n",
    "        try:\n",
    "            dt = datetime(century + yy, mm, dd)\n",
    "            return dt.strftime('%Y-%m-%d')\n",
    "        except Exception:\n",
    "            return \"0\"\n",
    "    return \"0\"\n",
    "\n",
    "try:\n",
    "    wi = Tk()\n",
    "    wi.withdraw()  # Hide the main window\n",
    "    wi.attributes('-topmost', True)  # Bring dialog to front (Jupyter sometimes hides it)\n",
    "    wi.update()\n",
    "\n",
    "    print(\"Opening file picker...\")\n",
    "    file = filedialog.askopenfilename(parent=wi, title=\"choose image\")\n",
    "    wi.destroy()  # Close window after selection\n",
    "\n",
    "    if not file:\n",
    "        raise Exception(\"No file selected\")\n",
    "\n",
    "    name = file\n",
    "    print(\"Selected:\", name)\n",
    "\n",
    "    input_path = name\n",
    "    input = Image.open(input_path)\n",
    "    output = remove(input)\n",
    "    img_array = np.array(output)\n",
    "    img = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)\n",
    "    blurred = cv2.blur(img, (5,5))\n",
    "    kernel = np.array([[-1,-1,-1] ,[-1,9,-1],[-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(blurred, -1, kernel)\n",
    "    canny = cv2.Canny(sharpened, 50, 200)\n",
    "    pts = np.argwhere(canny>0)\n",
    "    if pts.size == 0:\n",
    "        cropped = img\n",
    "    else:\n",
    "        y1,x1 = pts.min(axis=0)\n",
    "        y2,x2 = pts.max(axis=0)\n",
    "        cropped = img[y1:y2, x1:x2]\n",
    "    w,h,c=cropped.shape\n",
    "    o=int(w/2)\n",
    "    i=int(h/2.5)\n",
    "    n=int(h/6)\n",
    "    cr=cropped[n-13:i+15,o:]  # Extended bottom boundary to capture more address text\n",
    "    cropped_img=cropped[i+8:,o+10:]\n",
    "    \n",
    "    # Split the text region into names and address\n",
    "    cr_height = cr.shape[0]\n",
    "    split_point = int(cr_height * 0.52)  # Split at 52% (names in top, address in bottom)\n",
    "    names_region = cr[0:split_point, :]\n",
    "    address_region_raw = cr[split_point:, :]\n",
    "    \n",
    "    # Apply preprocessing to improve address region quality\n",
    "    address_region = cv2.GaussianBlur(address_region_raw, (3, 3), 0)\n",
    "    address_region = cv2.convertScaleAbs(address_region, alpha=1.3, beta=10)  # Increase contrast and brightness\n",
    "    \n",
    "    # Save the names region to newimg.png\n",
    "    cv2.imwrite(\"newimg.png\", names_region)\n",
    "    # Save the address region to address.png\n",
    "    cv2.imwrite(\"address.png\", address_region)\n",
    "    # Save the ID number region to id_card.png\n",
    "    cv2.imwrite(\"id_card.png\",cropped_img)\n",
    "\n",
    "    # Read NAMES region using Tesseract (path 1)\n",
    "    text_names=pytesseract.image_to_string(names_region,lang='ara',config='--psm 11 --oem 3')\n",
    "    splited_names=text_names.split('\\n')\n",
    "\n",
    "    arabic_digits = [\"٠\", \"١\", \"٢\", \"٣\", \"٤\", \"٥\", \"٦\", \"٧\", \"٨\", \"٩\"]\n",
    "    pun=set(string.punctuation)\n",
    "\n",
    "    # One EasyOCR reader for address + ID (and fallback names)\n",
    "    s = easyocr.Reader(['ar','ar'])\n",
    "    d_names = s.readtext(names_region, detail=0, text_threshold=0.18, width_ths=0.9, low_text=0.17)\n",
    "    # Optimized parameters for better address reading\n",
    "    d_address = s.readtext(address_region, detail=0, text_threshold=0.15, width_ths=0.7, low_text=0.15, paragraph=True)\n",
    "\n",
    "    state=0\n",
    "    if len(text_names.split('\\n'))==4:\n",
    "        state=1\n",
    "        print(state)\n",
    "        firstname=splited_names[0] if len(splited_names) > 0 else \"0\"\n",
    "        secondname=splited_names[2] if len(splited_names) > 2 else \"0\"\n",
    "\n",
    "        # Address from EasyOCR (address region)\n",
    "        address_easyocr = ' '.join(d_address) if len(d_address) > 0 else \"\"\n",
    "\n",
    "        # Use EasyOCR result for address\n",
    "        address = choose_address(\"\", address_easyocr)\n",
    "        # Remove cross-line duplicates\n",
    "        address = _remove_cross_line_duplicates(address)\n",
    "\n",
    "        data[\"first name\"] = firstname\n",
    "        data[\"seconed name\"] = secondname\n",
    "        data[\"address\"] = address\n",
    "\n",
    "        for i in data:\n",
    "            if i == None:\n",
    "                data[\"error\"] = \"1\"\n",
    "                break\n",
    "            else:\n",
    "                imgs = cv2.imread('id_card.png',0)\n",
    "                gauss = cv2.GaussianBlur(imgs, (7,7), 0)\n",
    "                unsharp_image = cv2.addWeighted(imgs, 2, gauss, -1, 0)\n",
    "                o=s.readtext(unsharp_image, detail = 0,text_threshold = 0.27\n",
    "                ,width_ths = 0.8,low_text= .008)\n",
    "                if len(o) == 1:\n",
    "                    data[\"id\"] = o[0]\n",
    "                elif len(o) == 0:\n",
    "                    data[\"id\"] = \"0\"\n",
    "                elif len(o) > 1:\n",
    "                    data[\"id\"]=max(o, key=len)\n",
    "\n",
    "            break\n",
    "\n",
    "    elif state==0:\n",
    "        state=2\n",
    "        imgs = cv2.imread('id_card.png',0)\n",
    "        # Enhanced preprocessing for better digit recognition\n",
    "        imgs = cv2.medianBlur(imgs, 3)\n",
    "        gauss = cv2.GaussianBlur(imgs, (5,5), 0)\n",
    "        unsharp_image = cv2.addWeighted(imgs, 2.2, gauss, -1.2, 0)\n",
    "        # Additional contrast enhancement\n",
    "        unsharp_image = cv2.convertScaleAbs(unsharp_image, alpha=1.4, beta=5)\n",
    "\n",
    "        # Use already-read EasyOCR result for the text region\n",
    "        d = d_names\n",
    "\n",
    "        # Address from EasyOCR (address region) - keep all tokens to capture leading numbers\n",
    "        address_easyocr = ' '.join(d_address) if len(d_address) > 0 else \"\"\n",
    "\n",
    "        for i in d:\n",
    "            if i in arabic_digits:\n",
    "                break\n",
    "            else:\n",
    "                my_data = ','.join(d)\n",
    "                split_list = my_data.split(',')\n",
    "                data[\"first name\"] = split_list[0] if len(split_list) > 0 else \"0\"\n",
    "                # Second name should include all remaining name parts (not just one word)\n",
    "                data[\"seconed name\"] = ','.join(split_list[1:]) if len(split_list) > 1 else \"0\"\n",
    "                # Clean up commas in second name\n",
    "                data[\"seconed name\"] = data[\"seconed name\"].replace(\",\", \" \").strip()\n",
    "\n",
    "                # Use EasyOCR result for address\n",
    "                data[\"address\"] = choose_address(\"\", address_easyocr)\n",
    "                # Remove cross-line duplicates\n",
    "                data[\"address\"] = _remove_cross_line_duplicates(data[\"address\"])\n",
    "\n",
    "                # Clean up any remaining brackets/quotes\n",
    "                data[\"address\"] = data[\"address\"].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\",\"\")\n",
    "\n",
    "        # Enhanced OCR parameters for better digit recognition\n",
    "        o=s.readtext(unsharp_image, detail = 0, text_threshold = 0.25,\n",
    "                     width_ths = 0.7, low_text= 0.01, paragraph=False)\n",
    "        print(state)\n",
    "        if o == None or d == None:\n",
    "            state = 4\n",
    "            data[\"error\"] = \"1\"\n",
    "        else:\n",
    "            if len(o) == 1:\n",
    "                data[\"id\"] = o[0]\n",
    "            elif len(o) == 0:\n",
    "                data[\"id\"] = \"0\"\n",
    "            elif len(o) > 1:\n",
    "                    data[\"id\"]=max(o, key=len)\n",
    "\n",
    "    elif state == 4:\n",
    "        data[\"error\"] = \"1\"\n",
    "    if len(str(data[\"id\"]))<20:\n",
    "        data[\"error\"]=\"1\"\n",
    "    for i in data[\"first name\"]:\n",
    "        if i in arabic_digits or i in pun:\n",
    "            data[\"first name\"] = data[\"first name\"].replace(i, \"\")\n",
    "    for i in data[\"seconed name\"]:\n",
    "        if i in arabic_digits or i in pun:\n",
    "            data[\"seconed name\"] = data[\"seconed name\"].replace(i, \"\")\n",
    "\n",
    "    # Validation: second name should be longer than first name\n",
    "    if len(data[\"seconed name\"]) <= len(data[\"first name\"]):\n",
    "        data[\"first name\"], data[\"seconed name\"] = data[\"seconed name\"], data[\"first name\"]\n",
    "\n",
    "    def _word_parts(value: str) -> list[str]:\n",
    "        return [part for part in (value or \"\").split() if part]\n",
    "\n",
    "    first_parts = _word_parts(data[\"first name\"])\n",
    "    second_parts = _word_parts(data[\"seconed name\"])\n",
    "\n",
    "    if len(first_parts) > 3:\n",
    "        data[\"error\"] = \"1\"\n",
    "    if len(second_parts) <= 1:\n",
    "        data[\"error\"] = \"1\"\n",
    "\n",
    "    ar=['ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي']\n",
    "    for i in str(data[\"id\"]):\n",
    "        if i in ar or i in pun:\n",
    "            data[\"id\"]=str(data[\"id\"]).replace(i, \"\")\n",
    "\n",
    "    arabic_string = str(data[\"id\"])\n",
    "\n",
    "    # Use regular expression to extract individual numbers\n",
    "    regex = r'[٠-٩]+'\n",
    "    matches = re.findall(regex, arabic_string)\n",
    "\n",
    "    # Reverse the order of the matches\n",
    "    matches.reverse()\n",
    "\n",
    "    # Concatenate the matches into a single string\n",
    "    concatenated_string = ''.join(matches)\n",
    "\n",
    "    # Convert the concatenated string to an integer\n",
    "    if concatenated_string:\n",
    "        integer_value = int(concatenated_string.translate(_ARABIC_TO_WESTERN))\n",
    "        data[\"id\"]=integer_value\n",
    "\n",
    "    data[\"birthdate\"] = _extract_birthdate_from_id(data[\"id\"])\n",
    "    \n",
    "    # Validate birthdate - if invalid, set error flag\n",
    "    if data[\"birthdate\"] == \"0\":\n",
    "        data[\"error\"] = \"1\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    data['id'] = 0\n",
    "    data['error'] = 1\n",
    "    data[\"birthdate\"] = \"0\"\n",
    "\n",
    "for key, value in data.items():\n",
    "    print(key, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
